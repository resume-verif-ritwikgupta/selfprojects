# -*- coding: utf-8 -*-
"""mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NEqStPcKs74diDrtmLJaXQDYwdIaoChT
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.utils.data import Dataset, TensorDataset
from torch import optim
import copy
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import matplotlib.pyplot as plt
import os
import numpy as np
import random
from torch.utils.data import random_split

T = transforms.Compose([
                        transforms.ToTensor()
])

mnist_trainset = datasets.MNIST(root = './data', train = True, download = True, transform = T)
mnist_testset = datasets.MNIST(root = './data', train = False, download = True, transform = T)
mnist_trainset, mnist_valset= random_split(mnist_trainset, [50000,10000])
len(mnist_trainset)
len(mnist_testset)

print(len(mnist_trainset))
print(len(mnist_testset))
print(len(mnist_valset))

train_length = len(mnist_trainset)
test_length = len(mnist_testset)
val_length = len(mnist_valset)

bs = 64
train_dl =  DataLoader(mnist_trainset, batch_size = bs)
val_dl = DataLoader(mnist_valset, batch_size = bs)
test_dl = DataLoader(mnist_testset, batch_size = bs)

plt.imshow(mnist_trainset[8000][0][0], cmap = "gray")

class NN(nn.Module):
    def __init__(self, hidden_layer_size = 128):
        super(NN, self).__init__()
        self.fc1 = nn.Linear(784, hidden_layer_size)
        self.fc2 = nn.Linear(hidden_layer_size, 10)

    def forward(self, X):
        h1 = torch.flatten(X, start_dim = 1, end_dim = -1)
        a1= self.fc1(h1)
        h2= torch.relu(a1)
        a2= self.fc2(h2)
        return a2

nnet = NN()

class model():
  def __init__(self, NN, epochs, lr):
        self.nnet = NN
        self.epochs = epochs
        self.lr = lr
        self.test_loss= 0
        self.train_loss_memory = []
        self.val_loss_memory = []
        self.train_accuracy = []
        self.val_accuracy = []
        self.test_accuracy = 0 
  
  def train(self):
    nnet = self.nnet
    optimiser = optim.SGD(self.nnet.parameters(), lr = self.lr, momentum = 0.9)
    loss_criterion = nn.CrossEntropyLoss()

    for epoch in range(self.epochs):
      nnet.train()
      tot_loss = 0
      train_correct = 0

      for batch in train_dl :
        data = batch[0]
        label = batch[1]
        optimiser.zero_grad()
        output = nnet(data)
        loss = loss_criterion(output, label)
        tot_loss += loss.item()
        loss.backward()
        optimiser.step()
        _, pred = torch.max(output.data, 1)
        train_correct += (pred == label).sum().item()
      
      self.train_loss_memory.append(tot_loss/train_length)
      self.train_accuracy.append((1 - tot_loss/train_length)*100)
      
      val_loss = 0
      nnet.eval()
      val_correct = 0

      for batch in val_dl :
        data = batch[0]
        label = batch[1]
        optimiser.zero_grad()
        output = nnet(data)
        loss = loss_criterion(output, label)
        val_loss += loss.item()
        loss.backward()
        optimiser.step()
        _, pred = torch.max(output.data, 1)
        val_correct += (pred == label).sum().item()

      print(f'Epoch {epoch} --> Train loss : {tot_loss/train_length} Val loss : {val_loss/val_length}')
      
      self.val_loss_memory.append(val_loss/val_length)
      self.val_accuracy.append((1 - val_loss/val_length)*100)

  def test(self):
    self.test_loss = 0
    test_correct = 0
    loss_criterion = nn.CrossEntropyLoss()

    with torch.no_grad():
      for batch in test_dl :
        data = batch[0]
        label = batch[1]
        output = self.nnet(data)

        _, pred = torch.max(output.data, 1)
        test_correct += (pred == label).sum().item()
        loss = loss_criterion(output, label)
        self.test_loss += loss.item()
    
    self.test_accuracy = 100*test_correct/test_length
    print(test_correct)
    print(test_length)
    print("Test Set Accuracy is : ", self.test_accuracy)

model1= model(nnet, 20, lr=1e-3)
model1.train()

model1.test()

plt.subplots(figsize=(8,6))
plt.plot(model1.train_loss_memory, color='green', label ='Train Loss')
plt.plot(model1.val_loss_memory, color='red', label='Validation Loss')

plt.legend()
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

plt.subplots(figsize=(8,6))
plt.plot(model1.train_accuracy)
plt.plot(model1.val_accuracy)
plt.xlabel("Number of Epochs")
plt.legend(["Training Accuracy","Validation Accuracy"])
plt.ylabel("Accuracy in %")
plt.show()

"""#Best Hidden Layer Size"""

nnet2 = NN(hidden_layer_size = 32)
nnet3 = NN(hidden_layer_size = 64)
nnet4 = NN(hidden_layer_size = 256)
nnet5 = NN(hidden_layer_size = 512)

model2 = model(nnet2, 20, 1e-3)
model3 = model(nnet3, 20, 1e-3)
model4 = model(nnet4, 20, 1e-3)
model5 = model(nnet5, 20, 1e-3)

model2.train()

model3.train()

model4.train()

model5.train()

models = [model2, model3, model1, model4, model5]
val_losses = []

for mod in models :
  val_losses.append(mod.val_loss_memory[::-1][0])

plt.subplots(figsize=(8,6))
plt.plot([2**i for i in range(5,10)], val_losses, '-o', color='blue')
plt.xlabel('Hidden Layer Size')
plt.ylabel('Validation Loss')
plt.show()

"""#Best Learning rate"""

nnet6 = NN(hidden_layer_size = 128)
nnet7 = NN(hidden_layer_size = 128)
nnet8 = NN(hidden_layer_size = 128)
nnet9 = NN(hidden_layer_size = 128)

model6 = model(nnet6, 20, 1e-1)
model7 = model(nnet7, 20, 1e-2)
model8 = model(nnet8, 20, 1e-4)
model9 = model(nnet9, 20, 1e-5)

model6.train()

model7.train()

model8.train()

model9.train()

best_lr_models = [model9, model8, model1, model7, model5]
model_lrs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]

end_val_loss = []
for mod in best_lr_models:
    end_val_loss.append(mod.val_loss_memory[::-1][0])

plt.subplots(figsize=(8,6))
plt.plot(np.log(model_lrs)/2.303, val_losses, '-o', color='blue')
plt.xlabel('Learning Rate')
plt.ylabel('Last Validation Loss')
plt.show()

"""#Best Model"""

nn_run_best = NN(hidden_layer_size= 512)
model_run_best = model(nn_run_best, epochs = 20, lr = 1e-1)
model_run_best.train()

model_run_best.test()

"""#Extra Credit"""

def cnet():
  model = nn.Sequential(
      nn.Conv2d(in_channels = 1, #grey only
                out_channels = 6,#number of kernels 
                kernel_size = 5, #5x5 squares
                padding = 2      #so that we don't neglect pixels at the border
                ),
      nn.ReLU(),
      nn.AvgPool2d(2, stride = 2),

      nn.Conv2d(6, 20, 5, padding = 0),
      nn.ReLU(),
      nn.AvgPool2d(2, stride = 2),

      nn.Flatten(),
      nn.Linear(500, #out_channels were 20 in the last conv layer, multiply it with 5x5 kernel size
                400),
      nn.ReLU(),
      nn.Linear(400, 160),
      nn.ReLU(),
      nn.Linear(160, 70),
      nn.ReLU(),
      nn.Linear(70, 10)
  )
  return model

class NN(nn.Module) :
  def __init__(self, hidden_layer = 128):
    super(NN, self).__init__()
    self.fc1 = nn.Linear(in_features = 1, out_features = hidden_layer)
    self.fc2 = nn.Linear(in_features = hidden_layer, out_features = 10)

  def forward(self, data) :
    x = F.relu(self.fc1(data))
    x = self.fc2(x)
    return x

nnet = NN()

epochs = 50
lr = 1e-3

loss_criterion = nn.CrossEntropyLoss()
optimiser = optim.SGD(nnet.parameters(), lr = lr)

def train():
  train_loss_recorder = np.empty((epochs, 1))
  val_loss_recorder = np.empty((epochs, 1))
  for epoch in range(epochs):
    nnet.train()
    tot_loss = 0
    for batch in train_dl :
      data = batch[0]
      label = batch[1]
      optimiser.zero_grad()
      output = nnet(data)
      loss = loss_criterion(output, label)
      tot_loss += loss.item()
      loss.backward()
      optimiser.step()
    val_loss = 0
    nnet.eval()
    for batch in val_loader :
      data = batch[0]
      label = batch[1]
      optimiser.zero_grad()
      output = nnet(data)
      loss = loss_criterion(output, label)
      val_loss += loss.item()
      loss.backward()
      optimiser.step()
    print(f'Epoch {epoch} --> Train loss : {tot_loss/16} Val loss : {val_loss/16}')
    np.append(train_loss_recorder, [epoch, tot_loss/16])
    np.append(val_loss_recorder,[epoch, val_loss/16])

def test():
  test_loss = 0
  correct = 0
  total = 0
  with torch.no_grad():
    for batch in test_loader :
      data = batch[0]
      label = batch[1]
      output = nnet(data)
      total += label.size(0)
      _, pred = torch.max(output.data, 1)
      correct += (pred == label).sum().item()
  print('Accuracy on test set : ' + str(100* correct/total))

def val(model, data):
  total = 0
  correct = 0
  for betch in data:
    images = betch[0]
    labels = betch[1]
    x = model(images)
    value, pred = torch.max(x, 1)
    total += x.size(0) #basically batch size
    correct += torch.sum(pred == labels)
  return correct*100./total

epochs = 30
learning_rate = 0.001

def train(epochs = 10, lr = 0.001) :
  accuracy_memory = []
  cnn = cnet()
  loss_criterion = nn.CrossEntropyLoss()
  optimiser = optim.SGD(cnn.parameters(), lr = lr)
  max_accuracy = 0
  
  for epoch in range(epochs) :
    for batch in train_dl:
      images = batch[0]
      labels = batch[1]
      optimiser.zero_grad()
      pred = cnn(images)
      loss = loss_criterion(pred, labels)
      loss.backward()
      optimiser.step()
    accuracy = float(val(cnn, val_dl))
    accuracy_memory.append(accuracy)
    if accuracy > max_accuracy :
      best_model = copy.deepcopy(cnn)
      max_accuracy = accuracy
    print("Epoch: ", epoch+1, " Accuracy: ", accuracy, "%")
  
  plt.plot(accuracy_memory)
  return best_model

vroom = train()